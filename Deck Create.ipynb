{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from io import BytesIO\n",
    "from ISR.models import RDN;\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from YDKReader import Reader\n",
    "from IPython.display import clear_output\n",
    "\n",
    "database_filename = \"database.csv\"\n",
    "database_folder = \"./Images Database/\"\n",
    "\n",
    "database = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Update the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_database():\n",
    "    '''\n",
    "    Update cards database for newer cards.\n",
    "    '''\n",
    "    print(\"Updating Database....\")\n",
    "    response = requests.get(\"https://db.ygoprodeck.com/api/v7/cardinfo.php\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success\")\n",
    "        card = response.json()\n",
    "        df = pd.json_normalize(card['data'], record_path=['card_images'], meta=['name'])\n",
    "        df = df[1:]\n",
    "        df['upscaled_image'] = \" \"\n",
    "        df = df.set_index('id')\n",
    "        df.index = df.index.astype(str)\n",
    "        #old_df = pd.read_csv(database_filename, index_col=\"id\")\n",
    "        saved_images = os.listdir('./Images Database/')\n",
    "        # saved_images = old_df['upscaled_image']\n",
    "        for i in saved_images:\n",
    "            df.at[i.split('.png')[0], 'upscaled_image'] = './Images Database/' + i\n",
    "        df.to_csv('./' + database_filename)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Import the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_database():\n",
    "    '''\n",
    "    Import database. A dataframe object is then returned\n",
    "    '''\n",
    "    database = pd.read_csv(database_filename, index_col=\"id\")\n",
    "    database.index = database.index.astype(str)\n",
    "    #database.head()\n",
    "    return database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable Qt File explorer to fetch deck file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "\n",
    "from PyQt5.QtWidgets import QFileDialog\n",
    "\n",
    "def gui_fname(dir=None):\n",
    "    '''\n",
    "    Select a file via a dialog and return the file name.\n",
    "    '''\n",
    "    if dir is None: dir ='./'\n",
    "    fname = QFileDialog.getOpenFileName(None, \"Select data file...\", \n",
    "                dir, filter=\"All files (*);; SM Files (*.sm)\")\n",
    "    return fname[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Image setup fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(card_image:str):\n",
    "    '''\n",
    "    Create a GET request to fetch the card image. An image is then returned in bytes format.\n",
    "    '''\n",
    "    image = requests.get(card_image, timeout=120)\n",
    "    image = requests.get(card_image)\n",
    "    image = Image.open(BytesIO(image.content))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image_local(card_image:str):\n",
    "    '''\n",
    "    Upscale a given image url using RDN Super Resolution neural network. The image file path is then returned.\n",
    "    '''    \n",
    "    image = get_image(card_image)\n",
    "    lr_img = np.array(image)\n",
    "    rdn = RDN(weights='noise-cancel');\n",
    "    sr_image = rdn.predict(lr_img, by_patch_of_size=50)\n",
    "    result = Image.fromarray(sr_image)\n",
    "    file_path = database_folder + str(id) + \".png\"\n",
    "    result.save(file_path, \"PNG\")\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_card(id:str):\n",
    "    '''\n",
    "    Start processing a card given its id. The image file is then returned.\n",
    "    '''\n",
    "    proccessed = database.at[id, 'upscaled_image'] != \" \"\n",
    "\n",
    "    image_path = \"\"\n",
    "    if proccessed == False:\n",
    "        clear_output(wait=True)\n",
    "        print(database.at[id, 'name'])\n",
    "        print(\"Image not found.\\nProccessing now...\")\n",
    "        image_path = upscale_image_local(database.at[id, 'image_url'])\n",
    "        database.at[id, 'upscaled_image'] = image_path\n",
    "        database.to_csv(\"./\" + database_filename)\n",
    "    else:\n",
    "        #get the image directly\n",
    "        image_path = database.at[id, 'upscaled_image']\n",
    "        print(\"Image found at \" + image_path)\n",
    "\n",
    "    return Image.open(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Create .odg file and add the deck cards to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ODGEditor import ODGEditor\n",
    "import math\n",
    "def create_doc_file(folder_name, deck:dict, back_sleev=\"\"):\n",
    "    '''\n",
    "    Create a .odg file placing the file in 'folder_name', \n",
    "    adding cards in 'deck' and placing the desired sleeve (optional)\n",
    "    '''\n",
    "    odgEditor = ODGEditor(create_path=folder_name, deck=deck.get_result(), back_sleev=back_sleev)\n",
    "\n",
    "    page_number = math.ceil(sum(deck.get_result().values()) / 9.0)\n",
    "    odgEditor.add_pages(page_number)\n",
    "    odgEditor.insert_cards()\n",
    "    odgEditor.create_new_doc()\n",
    "\n",
    "    odgEditor.copy_card_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Execution of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing deck to work on\n",
    "file_name = gui_fname()\n",
    "file_name = './YDK Files/' + file_name.split('/')[-1]\n",
    "folder_name = file_name.split('.ydk')[0]\n",
    "\n",
    "deck = Reader(file_name)   # The deck data is read and a new folder for the deck is created\n",
    "back_sleev = \"\"\n",
    "\n",
    "# importing a deck sleeve if desired\n",
    "prompt = input(\"Do you want a back sleev? (y/n)\\n\")\n",
    "if prompt == 'y':\n",
    "    back_sleev = gui_fname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the deck cooking is done here\n",
    "database = import_database()\n",
    "\n",
    "for i, j in deck.get_result().items():\n",
    "    id = str(i)\n",
    "\n",
    "    if id not in database.index: database = update_database()\n",
    "    \n",
    "    card_name = database.at[id, 'name']\n",
    "    card_image = database.at[id, 'image_url']\n",
    "    print({card_name : card_image})\n",
    "    \n",
    "    image = process_card(id)   \n",
    "    #image.save(\"{}/{} x{}.png\".format(folder_name, \"({})\".format(id), j), \"PNG\")\n",
    "create_doc_file(folder_name, deck, back_sleev=back_sleev)\n",
    "\n",
    "print(\"Deck Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud API calling (not currently used due to limited quota)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale using the replicate Super Resolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image_replicate():\n",
    "    post_data = {\n",
    "        \"version\": \"9d91795e944f3a585fa83f749617fc75821bea8b323348f39cf84f8fd0cbc2f7\",\n",
    "        \"input\" : {\"image\" : card_image}\n",
    "    }\n",
    "    post_hearders = {\n",
    "        \"Authorization\" : \"Token [my token :)]\",\n",
    "        \"Content-Type\" : \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post('https://api.replicate.com/v1/predictions', data=json.dumps(post_data), headers=post_hearders)\n",
    "    if response.status_code != 201:\n",
    "        print(response.status_code)\n",
    "        print(response.content)\n",
    "    else:\n",
    "        print(response.json())\n",
    "        \n",
    "    #get the processed card after upscaling\n",
    "    response_dict = dict(response.json())\n",
    "\n",
    "    # wait until the process is finished\n",
    "    time.sleep(20)\n",
    "    output_image = requests.get(response_dict['urls']['get'], headers=post_hearders)\n",
    "\n",
    "    print(output_image.status_code)\n",
    "    print(output_image.content)\n",
    "\n",
    "    #get the image after prcoessing it\n",
    "    img_url = dict(output_image.json())['output'][0]['file']\n",
    "    \n",
    "    #caching the image link\n",
    "    database.at[id, \"upscaled_image\"] = img_url\n",
    "    database.to_csv('./' + database_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upscale using the waifu2x Super Resolution (model uploaded on DeepAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image_waifu2x():\n",
    "   response = requests.post(\n",
    "    \"https://api.deepai.org/api/waifu2x\",\n",
    "    data={\n",
    "        'image': card_image,\n",
    "    },\n",
    "    headers={'api-key': 'quickstart-QUdJIGlzIGNvbWluZy4uLi4K'}\n",
    "   )\n",
    "   time.sleep(10)\n",
    "   print(response.json())\n",
    "   img = response.json()['output_url']\n",
    "   import urllib.request\n",
    "   file_path = database_folder + str(id)\n",
    "   urllib.request.urlretrieve(img, file_path + \".png\")\n",
    "   return file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
